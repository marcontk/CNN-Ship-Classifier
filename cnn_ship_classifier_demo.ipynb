{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClasificaciÃ³n binaria de barcos mediante una CNN en AI::MXNet \n",
    "Ships in Satellite Imagery\n",
    "https://www.kaggle.com/datasets/rhammell/ships-in-satellite-imagery/data\n",
    "\n",
    "Marcelo Contreras Kohl, Julio-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.- Estructura del dataset\n",
    "Descargar el dataset  y cear el siguiente Ã¡rbol de directorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estructura del dataset\n",
    "MiDataset/ <br>\n",
    " â”œâ”€â”€ shipsnet/ <br>\n",
    "     â”œâ”€â”€ clase1/ <br>\n",
    "     â”‚    â”œâ”€â”€ img001.jpg <br>\n",
    "     â”‚    â”œâ”€â”€ img002.jpg <br>\n",
    "     â”‚    â””â”€â”€ ... <br>\n",
    "     â”œâ”€â”€ clase2/ <br>\n",
    "     â”‚    â”œâ”€â”€ img101.jpg <br>\n",
    "     â”‚    â”œâ”€â”€ img102.jpg <br>\n",
    "     â”‚    â””â”€â”€ ... <br>\n",
    "     â””â”€â”€ claseN/ <br>\n",
    "          â”œâ”€â”€ imgN01.jpg <br>\n",
    "          â”œâ”€â”€ imgN02.jpg <br>\n",
    "          â””â”€â”€ ... <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables de entorno\n",
    "Establecer variables de entorno para utilizar hilos que controlan paralelizaciÃ³n y ejecuciÃ³n en CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreadedEnginePerDevice"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "$ENV{MXNET_CPU_WORKER_NTHREADS} = 6;\n",
    "$ENV{MXNET_ENGINE_TYPE} = 'ThreadedEnginePerDevice';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MÃ³dulos requeridos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use strict;\n",
    "use warnings;\n",
    "\n",
    "use AI::MXNet qw(mx gluon);\n",
    "use AI::MXNet::NDArray qw(nd);\n",
    "use Scalar::Util qw(blessed);\n",
    "use List::Util qw(shuffle);\n",
    "\n",
    "use FindBin;\n",
    "use lib \"$FindBin::Bin/./lib\"; # Asegura que los mÃ³dulos .pm locales se encuentren\n",
    "\n",
    "use ImageFolderDataset;\n",
    "use ImageFolderDatasetSubset;\n",
    "use DataLoader;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.- Preparar DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificar clases y contar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clase minoritaria: class_1 (1000)\n",
      "Clase mayoritaria:  class_0 (3000)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use File::Find;\n",
    "\n",
    "my $root = 'MiDataset/shipsnet';\n",
    "my %count = ();\n",
    "\n",
    "find(\n",
    "    sub {\n",
    "        return unless -f && /\\.(jpg|png)$/i;\n",
    "        my $label = (split('/', $File::Find::dir))[-1];\n",
    "        $count{$label}++;\n",
    "    },\n",
    "    $root\n",
    ");\n",
    "\n",
    "# \n",
    "\n",
    "# Identificar la clase minoritaria\n",
    "my ($minor_class, $major_class) = sort { $count{$a} <=> $count{$b} } keys %count;\n",
    "\n",
    "print \"\\nClase minoritaria: $minor_class ($count{$minor_class})\\n\";\n",
    "print \"Clase mayoritaria:  $major_class ($count{$major_class})\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPerl->load_plugin('Chart::Plotly');\n",
    "\n",
    "# Crear datos para el histograma a partir de %count\n",
    "my @clases = sort keys %count;\n",
    "my @frecuencias = @count{@clases};\n",
    "\n",
    "my $trace = {\n",
    "    x => \\@clases,\n",
    "    y => \\@frecuencias,\n",
    "    type => 'bar',\n",
    "    marker => { color => 'skyblue' },\n",
    "    name => 'Frecuencia por clase',\n",
    "};\n",
    "\n",
    "my $layout = {\n",
    "    title => 'DistribuciÃ³n de imÃ¡genes por clase',\n",
    "    xaxis => { title => 'Clase' },\n",
    "    yaxis => { title => 'Cantidad de imÃ¡genes' },\n",
    "    bargap => 0.1,\n",
    "    width => 400,\n",
    "    height => 330,\n",
    "    margin => { l => 50, r => 50, b => 50, t => 50, pad => 0, },\n",
    "};\n",
    "\n",
    "my $plot = Chart::Plotly::Plot->new(\n",
    "    traces => [$trace],\n",
    "    layout => $layout\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers para dividir el dataset y transfomer\n",
    "### Usar mÃ³dulo \"ImageFolderDataset.pm\" para cargar imÃ¡genes desde una carpeta y las etiqueta automÃ¡ticamente segÃºn el subdirectorio (clase):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub split_dataset {\n",
    "    my ($dataset, %ratios) = @_;\n",
    "\n",
    "    my $random_state = delete $ratios{random_state};\n",
    "    srand($random_state) if defined $random_state;\n",
    "    use AI::MXNet qw(mx);\n",
    "    mx->random->seed($random_state);\n",
    "\n",
    "    # Asignar valores por defecto si no estÃ¡n definidos\n",
    "    $ratios{train} = 0.7  unless defined $ratios{train};\n",
    "    $ratios{val}   = 0.15 unless defined $ratios{val};\n",
    "    $ratios{test}  = 0.15 unless defined $ratios{test};\n",
    "\n",
    "    my $total = $dataset->len;\n",
    "    my @indices = shuffle(0 .. $total - 1);\n",
    "\n",
    "    my $train_end = int($ratios{train} * $total);\n",
    "    my $val_end   = $train_end + int($ratios{val} * $total);\n",
    "\n",
    "    my @train_indices = @indices[0 .. $train_end - 1];\n",
    "    my @val_indices   = @indices[$train_end .. $val_end - 1];\n",
    "    my @test_indices  = @indices[$val_end .. $#indices];\n",
    "\n",
    "    my $subset = sub {\n",
    "        my @idx = @_;\n",
    "        my (@subset_data);\n",
    "        for my $i (@idx) {\n",
    "            my ($img, $lbl, $path) = $dataset->at($i);\n",
    "            push @subset_data, { img => $img, label => $lbl, path => $path };\n",
    "        }\n",
    "\n",
    "        return ImageFolderDatasetSubset->new(\\@subset_data);\n",
    "    };\n",
    "\n",
    "    return (\n",
    "        train => $subset->(@train_indices),\n",
    "        validation => $subset->(@val_indices),\n",
    "        test => $subset->(@test_indices),\n",
    "    );\n",
    "}\n",
    "\n",
    "# TamaÃ±o de la imagen (definido una sola vez)\n",
    "use vars qw($image_size);  # Para usar en otra celda (Jupyter)\n",
    "$image_size = 80;          # Si cambias el dataset, solo modificas aquÃ­ para usar en redimensionar la imagen\n",
    "\n",
    "# Transformer (ejemplo: normalizaciÃ³n bÃ¡sica)\n",
    "sub transformer {\n",
    "    my ($img, $label) = @_;\n",
    "    $img = mx->image->imresize($img, $image_size, $image_size);  # Esto no cambia nada si ya es 80x80\n",
    "    $img = $img->astype('float32') / 255;\n",
    "    #$img = mx->nd->transpose($img, [2, 0, 1]);   # Asegura CHW (3,128,128)\n",
    "    return ($img, $label);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Cargar dataset completo desde el directorio y luego dividir (split_dataset) \n",
    "  - Split DataSet : 70% entrenamiento, 15% validaciÃ³n, 15% prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset completo \n",
    "my $full_dataset = ImageFolderDataset->new('MiDataset/shipsnet', \\&transformer);\n",
    "\n",
    "# Dividir dataset: \n",
    "my %datasets = split_dataset($full_dataset, train => 0.7, val => 0.15, test => 0.15, random_state => 42);\n",
    "\n",
    "print \"Train: \", $datasets{train}->len, \"\\n\";\n",
    "print \"Val:   \", $datasets{validation}->len, \"\\n\";\n",
    "print \"Test:  \", $datasets{test}->len, \"\\n\";\n",
    "\n",
    "print \"Dataset cargado y dividido exitosamente.\\n\";\n",
    "print \"Dataset dividido en \". keys(%datasets), \" subconjuntos: \", join(\", \", keys %datasets), \"\\n\";\n",
    "\n",
    "# use Data::Dumper;\n",
    "# print Dumper($datasets{train}{data}[0]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifcar inconsistencias en Subset train, test, validation (opcional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my $M_img = 5;\n",
    "\n",
    "for my $subset (qw(train validation test)) {\n",
    "    my $dataset = $datasets{$subset};\n",
    "    print \"\\nPrimeros $M_img ejemplos del subconjunto '$subset':\\n\";\n",
    "\n",
    "    for my $i (0 .. $M_img) {\n",
    "        my ($img, $label, $path) = $dataset->at($i);\n",
    "        unless (defined $img && defined $label) {\n",
    "            warn \"Ejemplo $i indefinido\\n\";\n",
    "            next;\n",
    "        }\n",
    "        print \"Ejemplo $i: Etiqueta = $label | Ruta = $path\\n\";\n",
    "        print \"Dimensiones: \", join(\"x\", @{$img->shape}), \"\\n\";\n",
    "    }\n",
    "}\n",
    "\n",
    "print \"--------------------------\\n\";\n",
    "\n",
    "# Verificar consistencia de etiquetas en los subconjuntos\n",
    "print \"Verificando consistencia de etiquetas en los subconjuntos...\\n\";\n",
    "\n",
    "use File::Spec;\n",
    "\n",
    "my $label_map = $full_dataset->{label_map};\n",
    "my $inconsistencias_globales = 0;\n",
    "\n",
    "for my $subset (qw(train validation test)) {\n",
    "    my $dataset = $datasets{$subset};\n",
    "    print \"\\nðŸ“‚ Primeros $M_img ejemplos del subconjunto '$subset':\\n\";\n",
    "\n",
    "    my $errores = 0;\n",
    "\n",
    "    my $N = ($datasets{$subset}->len) - 1;\n",
    "    print \"Total ejemplos en '$subset': $N - 1\\n\";\n",
    "\n",
    "    for my $i (0 .. $N) {\n",
    "        my ($img, $label, $path) = $dataset->at($i);\n",
    "        unless (defined $img && defined $label && defined $path) {\n",
    "            warn \"âš ï¸  Ejemplo $i indefinido o incompleto\\n\";\n",
    "            next;\n",
    "        }\n",
    "\n",
    "        print \"Ejemplo $i: Etiqueta = $label | Ruta = $path\\n\";\n",
    "        print \"Dimensiones: \", join(\"x\", @{$img->shape}), \"\\n\";\n",
    "\n",
    "        # Extraer nombre del subdirectorio que representa la clase\n",
    "        my @dirs = File::Spec->splitdir($path);\n",
    "        my $dir_label = $dirs[-2];  # se asume ruta tipo .../class_0/image.png\n",
    "\n",
    "        if (exists $label_map->{$dir_label}) {\n",
    "            my $expected = $label_map->{$dir_label};\n",
    "            if ($label != $expected) {\n",
    "                warn \"âŒ Inconsistencia: etiqueta=$label vs esperada=$expected segÃºn ruta '$dir_label'\\n\";\n",
    "                $errores++;\n",
    "            }\n",
    "        } else {\n",
    "            warn \"âš ï¸  No se reconoce la clase '$dir_label' en label_map\\n\";\n",
    "            $errores++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if ($errores == 0) {\n",
    "        print \"âœ… Sin errores de consistencia en subset '$subset'\";\n",
    "    } else {\n",
    "        $inconsistencias_globales += $errores;\n",
    "    }\n",
    "}\n",
    "\n",
    "print \"\\n\\n\";\n",
    "\n",
    "\n",
    "if ($inconsistencias_globales == 0) {\n",
    "    print \"\\nðŸŽ‰ âœ… Todos los subconjuntos ('train', 'validation', 'test') estÃ¡n consistentes: sin errores de etiquetas vs directorios.\";\n",
    "} else {\n",
    "    print \"\\nâš ï¸  Se detectaron $inconsistencias_globales inconsistencias en los subconjuntos. Revisar detalles arriba.\";\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear subdirectorios y copiar imÃ¡genes del dataset dividido al disco "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use strict;\n",
    "use warnings;\n",
    "use File::Path qw(make_path);\n",
    "use File::Copy;\n",
    "use File::Basename qw(fileparse);\n",
    "use List::Util qw(shuffle);\n",
    "use feature 'say';\n",
    "\n",
    "# --- Crear directorios para split\n",
    "for my $split (qw(train validation test)) {\n",
    "    for my $class (qw(class_0 class_1)) {\n",
    "        make_path(\"MiDataset/shipsnet_split/$split/$class\");\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Copiar imÃ¡genes a sus nuevos directorios\n",
    "foreach my $split (qw(train validation test)) {\n",
    "\n",
    "    my $subset = $datasets{$split};\n",
    "\n",
    "    print \"Copiando imÃ¡genes al split '$split'...\\n\";\n",
    "\n",
    "    for my $item (@{$subset->{data}}) {\n",
    "        my $src = $item->{path};\n",
    "        #print \"Copiando $src...\\n\";\n",
    "        my $label = $item->{label} // (($src =~ /class_0/) ? 0 : 1);\n",
    "        my $class = ($label == 0) ? 'class_0' : 'class_1';\n",
    "        my ($basename) = fileparse($src);\n",
    "        my $dst = \"MiDataset/shipsnet_split/$split/$class/$basename\";\n",
    "        copy($src, $dst) or warn \"No se pudo copiar $src a $dst: $!\";\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contar las clases en los conjuntos: train, val y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub contar_clases {\n",
    "    my ($dataset) = @_;\n",
    "    my %conteo;\n",
    "    for my $i (0 .. $dataset->len - 1) {\n",
    "        my (undef, $label) = $dataset->at($i);\n",
    "        $conteo{$label}++;\n",
    "    }\n",
    "    return %conteo;\n",
    "}\n",
    "\n",
    "my %clases_train = contar_clases($datasets{train});\n",
    "print \"Train: \", join(\", \", map { \"Clase $_: $clases_train{$_}\" } sort keys %clases_train), \"\\n\";\n",
    "\n",
    "my $n_train = 0;\n",
    "$n_train += $_ for values %clases_train;\n",
    "print \"Total de imÃ¡genes en entrenamiento: $n_train\\n\";\n",
    "\n",
    "foreach my $subset (qw(train validation test)) {\n",
    "    my %cuenta = contar_clases($datasets{$subset});\n",
    "    print \"\\nDistribuciÃ³n en '$subset':\\n\";\n",
    "    foreach my $clase (sort keys %cuenta) {\n",
    "        print \"  Clase $clase: $cuenta{$clase} imÃ¡genes\\n\";\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancear clase solo para entrenamiento\n",
    "\n",
    "AugmentaciÃ³n: Iterar sobre los archivos de 'train/class_1', aplicar transformaciones y guardar como \"aug_XXX_*.png\"\n",
    "Las transformaciones en este celda son: \n",
    "- rotaciÃ³n en 90Â°\n",
    "- brillo en los tres canales rgb\n",
    "- ruido en rgb <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use Imager;\n",
    "use File::Glob ':glob';\n",
    "use File::Basename;\n",
    "use feature 'say';\n",
    "use Imager::Color;\n",
    "use List::Util qw(min max);\n",
    "\n",
    "use vars qw($root %count);\n",
    "\n",
    "my $class0_dir = \"$root\\_split/train/class_0\";\n",
    "my $class1_dir = \"$root\\_split/train/class_1\";\n",
    "print \"Clase 0: $class0_dir\\nClase 1: $class1_dir\\n\";\n",
    "\n",
    "my @imgs0 = bsd_glob(\"$class0_dir/*.{jpg,png}\", GLOB_BRACE);\n",
    "my @imgs1 = bsd_glob(\"$class1_dir/*.{jpg,png}\", GLOB_BRACE);\n",
    "\n",
    "my $n0 = scalar @imgs0;\n",
    "my $n1 = scalar @imgs1;\n",
    "my $diff = $n0 - $n1;\n",
    "print \"Clase 0: $n0\\nClase 1: $n1\\n\";\n",
    "\n",
    "if ($diff <= 0) {\n",
    "    print \"ðŸŸ¢ Ya estÃ¡ balanceado o class_1 es mayor\\n\";\n",
    "    exit;\n",
    "}\n",
    "print \"ðŸ”„ Generar $diff nuevas imÃ¡genes en class_1...\\n\";\n",
    "\n",
    "# Generar augmentaciones distribuidas entre las imÃ¡genes originales\n",
    "my $n_imgs     = scalar @imgs1;\n",
    "my $counter    = 0;\n",
    "my $generated  = 0;\n",
    "\n",
    "for my $i (0 .. $#imgs1) {\n",
    "    last if $generated >= $diff;\n",
    "\n",
    "    my $img = Imager->new();\n",
    "    $img->read(file => $imgs1[$i]) or die $img->errstr;\n",
    "    my $base = basename($imgs1[$i]);\n",
    "    $base =~ s/\\.(jpg|png)$//i;\n",
    "\n",
    "    # Llamar a la nueva funciÃ³n \"augmentar\" que devuelve 3 imÃ¡genes transformadas\n",
    "    my @aug_imgs = augmentar($img);\n",
    "\n",
    "    for my $aug_img (@aug_imgs) {\n",
    "        last if $generated >= $diff;\n",
    "\n",
    "        my $aug_filename = sprintf(\"%s/aug_%03d_%s.png\", $class1_dir, $counter, $base);\n",
    "        $aug_img->write(file => $aug_filename) or die $aug_img->errstr;\n",
    "        $counter++;\n",
    "        $generated++;\n",
    "        #say \"Generada imagen: $aug_filename\";\n",
    "    }\n",
    "}\n",
    "\n",
    "print \"âœ… Se generaron $counter nuevas imÃ¡genes augmentadas.\\n\";\n",
    "\n",
    "\n",
    "sub augmentar {\n",
    "    my ($img) = @_;\n",
    "\n",
    "    # RotaciÃ³n\n",
    "    my $rotated = $img->rotate(right => 90);\n",
    "\n",
    "    # Brillo\n",
    "    my $bright = $img->copy;\n",
    "    for my $y (0 .. $bright->getheight - 1) {\n",
    "        my @scanline = $bright->getscanline(y => $y);\n",
    "        for my $pixel (@scanline) {\n",
    "            my $r = List::Util::min(255, int($pixel->red   * 1.2));\n",
    "            my $g = List::Util::min(255, int($pixel->green * 1.2));\n",
    "            my $b = List::Util::min(255, int($pixel->blue  * 1.2));\n",
    "            $pixel = Imager::Color->new($r, $g, $b);\n",
    "        }\n",
    "        $bright->setscanline(y => $y, pixels => \\@scanline);\n",
    "    }\n",
    "\n",
    "    # Ruido\n",
    "    my $noisy = $img->copy;\n",
    "    for my $y (0 .. $noisy->getheight - 1) {\n",
    "        my @scanline = $noisy->getscanline(y => $y);\n",
    "        for my $pixel (@scanline) {\n",
    "            my $r = List::Util::max(0, List::Util::min(255, $pixel->red   + int(rand(20) - 10)));\n",
    "            my $g = List::Util::max(0, List::Util::min(255, $pixel->green + int(rand(20) - 10)));\n",
    "            my $b = List::Util::max(0, List::Util::min(255, $pixel->blue  + int(rand(20) - 10)));\n",
    "            $pixel = Imager::Color->new($r, $g, $b);\n",
    "        }\n",
    "        $noisy->setscanline(y => $y, pixels => \\@scanline);\n",
    "    }\n",
    "\n",
    "    return ($rotated, $bright, $noisy);\n",
    "}\n",
    "\n",
    "\n",
    "say \"âœ… Dataset reorganizado y listo para entrenamiento con aumento en class_1\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Cargar subdatasets particionados y balanceados en disco\n",
    "\n",
    "MiDataset/shipsnet_split/\n",
    "â”œâ”€â”€ train/\n",
    "â”‚   â”œâ”€â”€ class_0/\n",
    "â”‚   â””â”€â”€ class_1/\n",
    "â”œâ”€â”€ validation/\n",
    "â”‚   â”œâ”€â”€ class_0/\n",
    "â”‚   â””â”€â”€ class_1/\n",
    "â””â”€â”€ test/\n",
    "    â”œâ”€â”€ class_0/\n",
    "    â””â”€â”€ class_1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use ImageFolderDataset;\n",
    "\n",
    "print \"Cargando datasets desde '$root\\_split'...\\n\";\n",
    "\n",
    "my $train_dataset = ImageFolderDataset->new(\"$root\\_split/train\", \\&transformer);\n",
    "my $val_dataset   = ImageFolderDataset->new(\"$root\\_split/validation\", \\&transformer);\n",
    "my $test_dataset  = ImageFolderDataset->new(\"$root\\_split/test\", \\&transformer);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar DataLoader y hacer batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use DataLoader;\n",
    "\n",
    "my $batch_size = 32;\n",
    "\n",
    "my $train_loader = DataLoader->new(dataset => $train_dataset, batch_size => $batch_size, shuffle => 1);\n",
    "my $val_loader   = DataLoader->new(dataset => $val_dataset, batch_size => $batch_size, shuffle => 0);\n",
    "my $test_loader  = DataLoader->new(dataset => $test_dataset, batch_size => $batch_size, shuffle => 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar que los labels coincidan con la carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use Imager;\n",
    "use File::Glob ':glob';\n",
    "use File::Basename;\n",
    "use feature 'say';\n",
    "\n",
    "my $aug_dir = \"MiDataset/shipsnet_split/train/class_1\";\n",
    "my @aug_imgs = bsd_glob(\"$aug_dir/aug_*.png\");\n",
    "my @errores;\n",
    "\n",
    "say \"ðŸ” Verificando \", scalar(@aug_imgs), \" imÃ¡genes augmentadas en class_1...\";\n",
    "\n",
    "foreach my $img_path (@aug_imgs) {\n",
    "    my $img = Imager->new;\n",
    "    unless ($img->read(file => $img_path)) {\n",
    "        push @errores, $img_path;\n",
    "        warn \"âŒ No se pudo leer: $img_path â†’ \", $img->errstr, \"\\n\";\n",
    "        next;\n",
    "    }\n",
    "\n",
    "    my ($w, $h, $c) = ($img->getwidth, $img->getheight, $img->getchannels);\n",
    "    unless ($w == 80 && $h == 80 && $c == 3) {\n",
    "        push @errores, $img_path;\n",
    "        warn \"âš ï¸ Dimensiones invÃ¡lidas: $img_path â†’ ${w}x${h} canales=$c\\n\";\n",
    "    }\n",
    "}\n",
    "\n",
    "if (!@errores) {\n",
    "    say \"âœ… Todas las imÃ¡genes augmentadas son vÃ¡lidas y tienen tamaÃ±o 80x80x3.\";\n",
    "} else {\n",
    "    say \"âŒ Se encontraron errores en \", scalar(@errores), \" archivos:\";\n",
    "    say $_ for @errores;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Verficar una celda de prueba (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my ($data, $label) = $train_loader->next;\n",
    "print \"Batch shape [batch_size, height, width, channels]: \", join(\"x\", @{$data->shape}), \"\\n\";\n",
    "#print \"Labels: \", join(\", \", @$label), \"\\n\" if ref($label) eq 'ARRAY';\n",
    "my $labels = $label->aspdl->unpdl;\n",
    "$labels = [$labels] unless ref($labels) eq 'ARRAY';\n",
    "print \"Labels: \", join(\", \", @$labels), \"\\n\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener un batch del loader para verificar (Opcional)\n",
    "Guarda las imÃ¡genes en disco (solo visualizaciÃ³n) y se renderizan en la celda con html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use PDL;\n",
    "use PDL::Core ':Func';\n",
    "use PDL::IO::GD qw(write_true_png);\n",
    "use IPerl;\n",
    "use feature 'say';\n",
    "\n",
    "# Obtener un batch del loader\n",
    "my ($data, $label, $paths) = $train_loader->next;\n",
    "\n",
    "# Convertir labels a array Perl\n",
    "my $labels = $label->aspdl->unpdl;\n",
    "$labels = [$labels] unless ref($labels) eq 'ARRAY';\n",
    "\n",
    "# VisualizaciÃ³n HTML\n",
    "my $html = \"<div style='display: flex; flex-wrap: wrap;'>\\n\";\n",
    "\n",
    "for my $i (0 .. $#$labels) {\n",
    "    # Convertir imagen a PDL\n",
    "    my $img = $data->at($i)->aspdl->mv(0, 2);  # CHW â†’ HWC\n",
    "    $img *= 255 if $img->max <= 1;\n",
    "    $img = byte($img);\n",
    "\n",
    "    my $true_label = $labels->[$i];\n",
    "    my $path = $paths->[$i];\n",
    "    my ($basename) = $path =~ m{([^/]+\\.png)$};\n",
    "\n",
    "    # Guardar imagen con nombre informativo\n",
    "    my $filename = sprintf(\"batch_train_%02d_label_%d_%s\", $i, $true_label, $basename);\n",
    "    write_true_png($img, $filename);\n",
    "\n",
    "    $html .= \"<div style='margin: 5px; text-align: center; font-size: 11px; max-width: 80px;'>\n",
    "                <img src='$filename' width='80' style='border: 1px solid #ccc;'><br>\n",
    "                <b>Label:</b> $true_label<br>\n",
    "                <small style='word-break: break-all;'>$basename</small>\n",
    "              </div>\\n\";\n",
    "}\n",
    "\n",
    "$html .= \"</div>\";\n",
    "IPerl->html($html);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- DeniciÃ³n del Modelo:  red neuronal convolucional (CNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use AI::MXNet qw(mx);\n",
    "use AI::MXNet::Gluon::NN qw(nn);\n",
    "\n",
    "# 1. Contexto CPU (o GPU si quieres)\n",
    "my $ctx = mx->cpu;\n",
    "\n",
    "# 2. Definir la Red CNN\n",
    "my $net = nn->Sequential();\n",
    "$net->add(\n",
    "    # Primera capa convolucional: Conv2D + BatchNorm + MaxPool\n",
    "    nn->Conv2D(channels => 64, kernel_size => [3, 3], activation => 'relu', padding => [1,1],\n",
    "               weight_initializer => mx->init->Xavier(), \n",
    "               bias_initializer => 'zeros'),\n",
    "    nn->BatchNorm(),\n",
    "    nn->MaxPool2D(pool_size => [2, 2]),\n",
    "\n",
    "    # Segunda capa convolucional\n",
    "    nn->Conv2D(channels => 32, kernel_size => [3, 3], activation => 'relu', padding => [1,1],\n",
    "               weight_initializer => mx->init->Xavier(),\n",
    "               bias_initializer => 'zeros'),\n",
    "    nn->BatchNorm(),\n",
    "    nn->MaxPool2D(pool_size => [2, 2]),\n",
    "\n",
    "    # Tercera capa convolucional\n",
    "    nn->Conv2D(channels => 16, kernel_size => [3, 3], activation => 'relu', padding => [1,1],\n",
    "               weight_initializer => mx->init->Xavier(),\n",
    "               bias_initializer => 'zeros'),\n",
    "    nn->BatchNorm(),\n",
    "    nn->MaxPool2D(pool_size => [2, 2]),\n",
    "\n",
    "    # Aplanar + Dense + Dropout\n",
    "    #nn->GlobalAvgPool2D(),  # convierte cualquier tamaÃ±o a (1,1,C)\n",
    "    nn->Flatten(),\n",
    "\n",
    "    nn->Dense(64, activation => 'relu'),\n",
    "    nn->Dropout(0.5),\n",
    "\n",
    "    nn->Dense(32, activation => 'relu'),\n",
    "    nn->Dropout(0.5),\n",
    "\n",
    "    # Capa de salida (2 neuronas para clasificaciÃ³n binaria con SoftmaxCrossEntropyLoss)\n",
    "    nn->Dense(2)\n",
    ");\n",
    "\n",
    "# 3. Inicializar pesos\n",
    "$net->initialize(mx->init->Xavier(), ctx => $ctx);\n",
    "\n",
    "\n",
    "# 4. Activar pesos diferidos con un forward pass\n",
    "# ===============================================================\n",
    "# NOTA IMPORTANTE:\n",
    "# Las imÃ¡genes se cargan inicialmente en formato NHWC (Batch, Height, Width, Channels).\n",
    "# MXNet espera las entradas en formato NCHW (Batch, Channels, Height, Width).\n",
    "# AquÃ­ verificamos que la imagen tiene las dimensiones [Batch, 80, 80, 3]\n",
    "# para luego transponerla correctamente a [Batch, 3, 80, 80].\n",
    "#\n",
    "# Si no se transpone bien, la red falla con errores de tamaÃ±o en MaxPool2D.\n",
    "# Este paso asegura que la red procese correctamente imÃ¡genes 80x80 RGB.\n",
    "# ===============================================================\n",
    "\n",
    "# 4. Activar pesos diferidos con un forward pass\n",
    "my ($data, $label) = $train_loader->next;\n",
    "if ($data->shape->[1] == $image_size && $data->shape->[3] == 3) {\n",
    "    $data = $data->transpose([0, 3, 1, 2]);  # NHWC -> NCHW\n",
    "}\n",
    "$data  = $data->as_in_context($ctx);\n",
    "$label = $label->as_in_context($ctx);\n",
    "my $output = $net->($data);  # â† activa pesos diferidos\n",
    "\n",
    "# 5. Optimizer\n",
    "my $trainer = mx->gluon->Trainer(\n",
    "    $net->collect_params(),\n",
    "    'adam',\n",
    "    { learning_rate => 0.001, wd => 0.001 }\n",
    ");\n",
    "\n",
    "# 6. FunciÃ³n de pÃ©rdida\n",
    "my $loss_fn = AI::MXNet::Gluon::Loss::SoftmaxCrossEntropyLoss->new();\n",
    "\n",
    "# 7. Ver red\n",
    "print $net;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostrar pesos y bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for my $i (0 .. $#{$net}) {\n",
    "    my $layer = ${$net}[$i];\n",
    "    print \"[$i] \", ref($layer), \"\\n\";\n",
    "\n",
    "    # Verifica y muestra pesos\n",
    "    if ($layer->can('weight') and defined $layer->weight) {\n",
    "        my $w_data = eval { $layer->weight->data($ctx) };\n",
    "        if ($w_data) {\n",
    "            my $shape_w = join(\",\", @{ $w_data->shape });\n",
    "            print \"    Pesos: [$shape_w]\\n\";\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Verifica y muestra bias\n",
    "    if ($layer->can('bias') and defined $layer->bias) {\n",
    "        my $b_data = eval { $layer->bias->data($ctx) };\n",
    "        if ($b_data) {\n",
    "            my $shape_b = join(\",\", @{ $b_data->shape });\n",
    "            print \"    Bias: [$shape_b]\\n\";\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Entrenamiento y validaciÃ³n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- FunciÃ³n auxiliar F1-score por batch ---\n",
    "sub f1_score {\n",
    "    my ($preds, $labels) = @_;\n",
    "    my $pred_classes = $preds->argmax(axis => 1);\n",
    "    my $tp = (($pred_classes * $labels)->sum)->asscalar;\n",
    "    my $fp = ((($pred_classes == 1) * ($labels == 0))->sum)->asscalar;\n",
    "    my $fn = ((($pred_classes == 0) * ($labels == 1))->sum)->asscalar;\n",
    "    my $precision = $tp + $fp > 0 ? $tp / ($tp + $fp) : 0;\n",
    "    my $recall    = $tp + $fn > 0 ? $tp / ($tp + $fn) : 0;\n",
    "    my $f1 = $precision + $recall > 0 ? 2 * ($precision * $recall) / ($precision + $recall) : 0;\n",
    "    return $f1;\n",
    "}\n",
    "\n",
    "# --- F1 macro para la Ã©poca completa ---\n",
    "sub f1_score_macro {\n",
    "    my ($outputs, $labels) = @_;\n",
    "    my $preds = $outputs->argmax(axis => 1);\n",
    "    my $pred_array  = $preds->aspdl;\n",
    "    my $label_array = $labels->aspdl;\n",
    "    my ($tp0, $fp0, $fn0, $tp1, $fp1, $fn1) = (0, 0, 0, 0, 0, 0);\n",
    "\n",
    "    for my $i (0 .. $label_array->dim(0) - 1) {\n",
    "        my $true = $label_array->at($i);\n",
    "        my $pred = $pred_array->at($i);\n",
    "        if ($true == 0) {\n",
    "            $tp0++ if $pred == 0;\n",
    "            $fp1++ if $pred == 1;\n",
    "            $fn0++ if $pred == 1;\n",
    "        } else {\n",
    "            $tp1++ if $pred == 1;\n",
    "            $fp0++ if $pred == 0;\n",
    "            $fn1++ if $pred == 0;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    my $f1_0 = (2 * $tp0) / (2 * $tp0 + $fp0 + $fn0 + 1e-10);\n",
    "    my $f1_1 = (2 * $tp1) / (2 * $tp1 + $fp1 + $fn1 + 1e-10);\n",
    "    return ($f1_0 + $f1_1) / 2;\n",
    "}\n",
    "\n",
    "# --- Entrenamiento por Ã©poca ---\n",
    "sub train_one_epoch {\n",
    "    my ($epoch, $net, $train_loader, $trainer, $loss_fn, $ctx) = @_;\n",
    "\n",
    "    $net->train;\n",
    "\n",
    "    my $metric = mx->metric->Accuracy();\n",
    "    $metric->reset();\n",
    "\n",
    "    my ($train_loss, $num_batches) = (0, 0);\n",
    "\n",
    "    $train_loader->reset();\n",
    "    print \"\\nIniciando Ã©poca $epoch...\\n\";\n",
    "\n",
    "\n",
    "    while (my ($data, $label) = $train_loader->next) {\n",
    "        if ($data->shape->[1] == $image_size && $data->shape->[3] == 3) {\n",
    "            $data = $data->transpose([0, 3, 1, 2]);  # NHWC â†’ NCHW\n",
    "        }\n",
    "        $data  = $data->as_in_context($ctx);\n",
    "        $label = $label->as_in_context($ctx);\n",
    "\n",
    "        my $loss;\n",
    "        my $output;\n",
    "      \n",
    "        autograd->record(sub {\n",
    "            # Paso 1: calcular el loss normal\n",
    "            $output = $net->($data);\n",
    "            $loss = $loss_fn->($output, $label);\n",
    "\n",
    "            if ($num_batches == 0) {\n",
    "                #print \"Ejemplo pÃ©rdida: \", $loss->aspdl, \"\\n\";\n",
    "                #print \"PÃ©rdida ponderada (media): \", $loss->mean->asscalar, \"\\n\";\n",
    "\n",
    "                my $probs = $output->softmax;\n",
    "                my $preds = $probs->argmax(axis => 1);\n",
    "\n",
    "                #print \"== Primer batch de validaciÃ³n ==\\n\";\n",
    "                #print \"Probabilidades:\\n\", $probs->aspdl, \"\\n\";\n",
    "                #print \"Predicciones:\\n\", $preds->aspdl, \"\\n\";\n",
    "                #print \"Etiquetas verdaderas:\\n\", $label->aspdl, \"\\n\";\n",
    "            }\n",
    "\n",
    "            $loss->backward;\n",
    "        });\n",
    "\n",
    "        $trainer->step($data->shape->[0]);  # tamaÃ±o del batch\n",
    "\n",
    "        $train_loss += $loss->mean->asscalar;\n",
    "        $metric->update([$label], [$output]);\n",
    "        $num_batches++;\n",
    "    }\n",
    "\n",
    "    my ($name, $train_acc) = $metric->get();\n",
    "    my $avg_train_loss = $train_loss / $num_batches;\n",
    "\n",
    "    return ($avg_train_loss, $train_acc);\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- ValidaciÃ³n por Ã©poca ---\n",
    "sub validate_one_epoch {\n",
    "    my ($net, $val_loader, $loss_fn, $ctx, $epoch) = @_;\n",
    "    $net->eval;\n",
    "\n",
    "    my ($val_loss, $total, $f1_sum, $batches) = (0, 0, 0, 0);\n",
    "    my $val_metric = mx->metric->Accuracy();\n",
    "    $val_metric->reset();\n",
    "    $val_loader->reset();\n",
    "\n",
    "    my @all_outputs;\n",
    "    my @all_labels;\n",
    "\n",
    "    while (my ($data, $label) = $val_loader->next) {\n",
    "        if ($data->shape->[1] == $image_size && $data->shape->[3] == 3) {\n",
    "            $data = $data->transpose([0, 3, 1, 2]);\n",
    "        }\n",
    "        $data  = $data->as_in_context($ctx);\n",
    "        $label = $label->as_in_context($ctx);\n",
    "\n",
    "        my $output = $net->($data);\n",
    "        die \"ERROR: output es undef\\n\" unless defined $output;\n",
    "\n",
    "        my $loss = $loss_fn->($output, $label);\n",
    "        $val_loss += $loss->mean->asscalar;\n",
    "        $total    += $label->shape->[0];\n",
    "\n",
    "        \n",
    "        my $f1 = f1_score($output, $label);\n",
    "        $f1_sum += $f1;\n",
    "\n",
    "        $val_metric->update([$label], [$output]); \n",
    "        push @all_outputs, $output;\n",
    "       \n",
    "        push @all_labels,  $label;\n",
    "        $batches++;\n",
    "\n",
    "        my ($pred_label, $true_label) = ($output->argmax(axis => 1), $label);\n",
    "            #print \"Batch pred: \", $pred_label->aspdl, \"\\n\";\n",
    "            #print \"Batch true: \", $true_label->aspdl, \"\\n\";\n",
    "    }\n",
    "\n",
    "    my $avg_val_loss = $val_loss / $total;\n",
    "    my $avg_val_f1   = $f1_sum / $batches;\n",
    "    my (undef, $val_acc) = $val_metric->get();\n",
    "\n",
    "    my $f1_macro = 'N/A';\n",
    "    if (@all_outputs && @all_labels) {\n",
    "        my $concat_output = AI::MXNet::NDArray->concat(@all_outputs, { dim => 0 });\n",
    "        my $concat_label  = AI::MXNet::NDArray->concat(@all_labels,  { dim => 0 });\n",
    "        $f1_macro = f1_score_macro($concat_output, $concat_label);\n",
    "    }\n",
    "\n",
    "    return ($avg_val_loss, $f1_macro, $val_acc);\n",
    "}\n",
    "\n",
    "\n",
    "#======================================================\n",
    "# --- Bucle principal de entrenamiento + validaciÃ³n ---\n",
    "#======================================================\n",
    "use Time::HiRes qw(time);\n",
    "print \"Iniciando entrenamiento...\\n\";\n",
    "print time(), \" - \", scalar(localtime(time())), \"\\n\";\n",
    "\n",
    "\n",
    "my @acc_train_hist = ();\n",
    "my @loss_train_hist = ();\n",
    "my @acc_val_hist = ();\n",
    "my @loss_val_hist = ();\n",
    "my @f1_val_hist = ();\n",
    "\n",
    "\n",
    "# calcular actualizaciones por Ã©poca\n",
    "my $updates_per_epoch = int($n_train / $batch_size);  # 2800 / 32 = 87\n",
    "print \"Actualizaciones por Ã©poca: $updates_per_epoch\\n\";\n",
    "\n",
    "use AI::MXNet::LRScheduler;\n",
    "# --- Scheduler: reduce el LR en cada Ã©poca ---\n",
    "my $lr_scheduler = AI::MXNet::FactorScheduler->new(\n",
    "    step    => $updates_per_epoch * 5,  # cada N_updates actualizaciones (no Ã©pocas)\n",
    "    factor => 0.5, # el learning rate disminuye un 10% en cada â€œstepâ€ definido. 0.5 es mas agresivo   0.95 es ma conservador\n",
    "    # base_lr => 0.001, # valor tÃ­pico cuando se usa optimizador \"adam\"\n",
    "    # stop_factor_lr => 1e-6\n",
    ");\n",
    "print ref($lr_scheduler),\"\\n\";  # Debe ser 'AI::MXNet::FactorScheduler'\n",
    "\n",
    "# --- optimizador manualmente ---\n",
    "my $optimizer = AI::MXNet::Optimizer->create(\n",
    "    'adam',\n",
    "    learning_rate => 0.001,\n",
    "    lr_scheduler  => $lr_scheduler  # ðŸ‘ˆ esto sigue funcionando\n",
    ");\n",
    "\n",
    "\n",
    "# --- Trainer con scheduler ---\n",
    "my $trainer = mx->gluon->Trainer(\n",
    "    $net->collect_params(),\n",
    "    $optimizer\n",
    ");\n",
    "\n",
    "# --- Inicializar historial de learning rate ---\n",
    "my @lr_history = ();\n",
    "\n",
    "#--- Variables de control EarlyStoping ---\n",
    "my $best_val_loss = 1e8;  # 1e10 es algo muy alto\n",
    "my $patience = 5;\n",
    "my $patience_counter = 0;\n",
    "\n",
    "# --- NÃºmero de Ã©pocas ---\n",
    "my $epochs = 50;\n",
    "print \"NÃºmero de Ã©pocas: $epochs\\n\";\n",
    "\n",
    "for my $epoch (1 .. $epochs) {\n",
    "\n",
    "    print \"\\nâ³ Ã‰poca $epoch\\n\";\n",
    "\n",
    "    # --- Entrenamiento ---\n",
    "    my ($train_loss, $train_acc) = train_one_epoch($epoch, $net, $train_loader, $trainer, $loss_fn, $ctx);\n",
    "    printf(\"ðŸŸ¢ Entrenamiento: pÃ©rdida=%.4f, acc=%.2f%%\\n\", $train_loss, $train_acc*100);\n",
    "\n",
    "    # Obtener el learning rate actual despuÃ©s de cada Ã©poca\n",
    "    my $num_update = $epoch * $updates_per_epoch;\n",
    "    my $current_lr = $lr_scheduler->($num_update);\n",
    "    push @lr_history, $current_lr;\n",
    "\n",
    "\n",
    "    # --- ValidaciÃ³n ---\n",
    "    my ($val_loss, $val_f1, $val_acc) = validate_one_epoch($net, $val_loader, $loss_fn, $ctx, $epoch);\n",
    "    printf(\"ðŸ”µ ValidaciÃ³n: pÃ©rdida=%.4f, F1=%.4f, acc=%.2f%%\\n\", $val_loss, $val_f1, $val_acc*100);\n",
    "\n",
    "    # --- Monitorea el learning rate ---\n",
    "    # my $lr_actual = $trainer->learning_rate; # error: Too few arguments for method learning_rate (expected 2, got 1)\n",
    "    my $lr_actual = $trainer->{optimizer}->{learning_rate};\n",
    "\n",
    "    print \"Epoch $epoch - Learning Rate actual: $lr_actual\\n\";\n",
    "\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if ($val_loss < $best_val_loss) {\n",
    "        print \"MejorÃ³ val_loss: $val_loss (anterior: $best_val_loss)\\n\";\n",
    "        $best_val_loss = $val_loss;\n",
    "        $patience_counter = 0;\n",
    "        $net->save_parameters('best_model.params');  # Guarda mejores pesos\n",
    "    } else {\n",
    "        $patience_counter++;\n",
    "        print \"No mejorÃ³. Paciencia: $patience_counter / $patience\\n\";\n",
    "\n",
    "        if ($patience_counter >= $patience) {\n",
    "            print \"Early Stopping activado en Ã©poca $epoch.\\n\";\n",
    "            last;  # Salir del ciclo\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #--- Registro (historia) ---\n",
    "    push @loss_train_hist, $train_loss;\n",
    "    push @acc_train_hist,  $train_acc;\n",
    "    push @loss_val_hist, $val_loss;\n",
    "    push @acc_val_hist,  $val_acc;\n",
    "    push @f1_val_hist,   $val_f1;\n",
    "}\n",
    "\n",
    "print \"\\nðŸŽ‰ Entrenamiento finalizado.\\n\";\n",
    "print time(), \" - \", scalar(localtime(time())), \"\\n\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning rate history\n",
    "### Requiere que @lr_history exista (se llena durante el entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPerl->load_plugin('Chart::Plotly');\n",
    "use strict;\n",
    "use warnings;\n",
    "use PDL;\n",
    "use Chart::Plotly;\n",
    "use Chart::Plotly::Plot;\n",
    "use Chart::Plotly::Trace::Scatter;\n",
    "\n",
    "\n",
    "if (!@lr_history) {\n",
    "    warn \"No hay datos en \\@lr_history. Ejecuta el entrenamiento primero para registrar el LR.\\n\";\n",
    "} else {\n",
    "    my @epochs = (1 .. scalar @lr_history);\n",
    "    my @lrs    = map { sprintf \"%.6f\", $_ } @lr_history;\n",
    "\n",
    "    my $trace = {\n",
    "        x    => \\@epochs,\n",
    "        y    => \\@lrs,\n",
    "        # type => 'scatter',\n",
    "        mode => 'lines',\n",
    "        name => 'Learning Rate',\n",
    "        line => { color => 'royalblue', width => 2 },\n",
    "        marker => { size => 6 },\n",
    "    };\n",
    "\n",
    "    my $layout = {\n",
    "        title => 'EvoluciÃ³n del Learning Rate',\n",
    "        xaxis => { title => 'Ã‰poca' },\n",
    "        yaxis => { title => 'Learning Rate'}, # escala log para visualizar mejor la decay\n",
    "        width  => 700,\n",
    "        height => 380,\n",
    "        margin => { l => 70, r => 30, b => 50, t => 60 },\n",
    "    };\n",
    "\n",
    "    my $plot = Chart::Plotly::Plot->new(\n",
    "        traces => [$trace],\n",
    "        layout => $layout,\n",
    "    );\n",
    "\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPerl->load_plugin('Chart::Plotly');\n",
    "\n",
    "# --- Datos de ejemplo ---\n",
    "my @epochs = (1 .. 30);\n",
    "\n",
    "my @acc_train = map { sprintf \"%.5f\", $_ } @acc_train_hist;\n",
    "my @acc_val = map { sprintf \"%.5f\", $_ } @acc_val_hist;\n",
    "my @loss_train = map { sprintf \"%.5f\", $_ } @loss_train_hist;\n",
    "my @loss_val = map { sprintf \"%.5f\", $_ } @loss_val_hist;\n",
    "\n",
    "# --- Trazas ---\n",
    "my $trace_acc_train = {\n",
    "    x => [@epochs], y => [@acc_train], name => 'PrecisiÃ³n Entrenamiento',\n",
    "    mode => 'lines', line => { color => 'blue' }, type => 'scatter',\n",
    "};\n",
    "\n",
    "my $trace_acc_val = {\n",
    "    x => [@epochs], y => [@acc_val], name => 'PrecisiÃ³n ValidaciÃ³n',\n",
    "    mode => 'lines', line => { color => 'orange' }, type => 'scatter', \n",
    "};\n",
    "\n",
    "my $trace_loss_train ={\n",
    "    x => [@epochs], y => [@loss_train], name => 'PÃ©rdida Entrenamiento',\n",
    "    mode => 'lines', line => { color => 'green' }, xaxis => 'x2', yaxis => 'y2', type => 'scatter',    \n",
    "};\n",
    "\n",
    "my $trace_loss_val = {\n",
    "    x => [@epochs], y => [@loss_val], name => 'PÃ©rdida ValidaciÃ³n',\n",
    "    mode => 'lines', line => { color => 'red' }, xaxis => 'x2', yaxis => 'y2', type => 'scatter',    \n",
    "};\n",
    "\n",
    "# --- Layout con Subplots ---\n",
    " my $layout = {\n",
    "     title => 'PrecisiÃ³n y PÃ©rdida del Modelo',\n",
    "     grid => { rows => 1, columns => 2, pattern => 'independent' },\n",
    "     plot_bgcolor => 'white',\n",
    "     paper_bgcolor => 'white',\n",
    "     xaxis => { title => 'Ã‰pocas', gridcolor => '#e5ecf6' },\n",
    "     yaxis => { title => 'PrecisiÃ³n', range => [0.0, 1.0], gridcolor => '#e5ecf6' },\n",
    "     xaxis2 => { title => 'Ã‰pocas', gridcolor => '#e5ecf6' },\n",
    "     yaxis2 => { title => 'PÃ©rdida', gridcolor => '#e5ecf6' },\n",
    "     legend => { x => 1.05, y => 1 },\n",
    "     width => 950,\n",
    "     height => 450,\n",
    " };\n",
    "\n",
    "# --- Crear Plot ---\n",
    "my $plot = Chart::Plotly::Plot->new(\n",
    "    traces => [$trace_acc_train, $trace_acc_val, $trace_loss_train, $trace_loss_val],\n",
    "    layout => $layout\n",
    ");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporte de validaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub final_validation_report {\n",
    "    my ($net, $val_loader, $loss_fn, $ctx) = @_;\n",
    "\n",
    "    my (@all_preds, @all_labels);\n",
    "    my $total_loss = 0;\n",
    "    $val_loader->reset(); # Recorremos TODOS los datos otra vez desde el inicio.\n",
    "\n",
    "    while (my ($data, $label) = $val_loader->next) {\n",
    "        if ($data->shape->[1] == $image_size && $data->shape->[3] == 3) {\n",
    "            $data = $data->transpose([0, 3, 1, 2]);\n",
    "        }\n",
    "        $data  = $data->as_in_context($ctx);\n",
    "        $label = $label->as_in_context($ctx);\n",
    "\n",
    "        my $output = $net->($data);\n",
    "        my $loss   = $loss_fn->($output, $label);\n",
    "        $total_loss += $loss->mean->asscalar;\n",
    "\n",
    "        my $preds = $output->argmax(axis => 1);\n",
    "        push @all_preds,  @{$preds->aspdl->unpdl};\n",
    "        push @all_labels, @{$label->aspdl->unpdl};\n",
    "    }\n",
    "\n",
    "    my $n = scalar @all_labels;\n",
    "    my ($tp, $tn, $fp, $fn) = (0, 0, 0, 0);\n",
    "    for my $i (0..$n-1) {\n",
    "        my $t = $all_labels[$i];\n",
    "        my $p = $all_preds[$i];\n",
    "        if    ($t == 1 && $p == 1) { $tp++ }\n",
    "        elsif ($t == 0 && $p == 0) { $tn++ }\n",
    "        elsif ($t == 0 && $p == 1) { $fp++ }\n",
    "        elsif ($t == 1 && $p == 0) { $fn++ }\n",
    "    }\n",
    "\n",
    "    # MÃ©tricas\n",
    "    my $acc = ($tp + $tn) / $n;\n",
    "    my $precision_0 = $tn + $fn ? $tn / ($tn + $fn) : 0;\n",
    "    my $recall_0    = $tn + $fp ? $tn / ($tn + $fp) : 0;\n",
    "    my $f1_0        = $precision_0 + $recall_0 ? 2 * $precision_0 * $recall_0 / ($precision_0 + $recall_0) : 0;\n",
    "    my $support_0   = $tn + $fp;\n",
    "\n",
    "    my $precision_1 = $tp + $fp ? $tp / ($tp + $fp) : 0;\n",
    "    my $recall_1    = $tp + $fn ? $tp / ($tp + $fn) : 0;\n",
    "    my $f1_1        = $precision_1 + $recall_1 ? 2 * $precision_1 * $recall_1 / ($precision_1 + $recall_1) : 0;\n",
    "    my $support_1   = $tp + $fn;\n",
    "\n",
    "    my $macro_precision = ($precision_0 + $precision_1) / 2;\n",
    "    my $macro_recall    = ($recall_0 + $recall_1) / 2;\n",
    "    my $macro_f1        = ($f1_0 + $f1_1) / 2;\n",
    "\n",
    "    my $weighted_precision = ($precision_0 * $support_0 + $precision_1 * $support_1) / $n;\n",
    "    my $weighted_recall    = ($recall_0 * $support_0 + $recall_1 * $support_1) / $n;\n",
    "    my $weighted_f1        = ($f1_0 * $support_0 + $f1_1 * $support_1) / $n;\n",
    "\n",
    "    # Mostrar reporte\n",
    "    printf \"\\n              precision    recall  f1-score   support\\n\";\n",
    "    printf \"     class_0     %6.2f     %6.2f     %6.2f     %6d\\n\", $precision_0, $recall_0, $f1_0, $support_0;\n",
    "    printf \"     class_1     %6.2f     %6.2f     %6.2f     %6d\\n\", $precision_1, $recall_1, $f1_1, $support_1;\n",
    "    printf \"\\n    accuracy                         %6.2f     %6d\\n\", $acc, $n;\n",
    "    printf \"   macro avg     %6.2f     %6.2f     %6.2f     %6d\\n\", $macro_precision, $macro_recall, $macro_f1, $n;\n",
    "    printf \"weighted avg     %6.2f     %6.2f     %6.2f     %6d\\n\\n\", $weighted_precision, $weighted_recall, $weighted_f1, $n;\n",
    "\n",
    "    #my $avg_loss = $total_loss / $val_loader->num_batches;\n",
    "    #printf \"\\nAverage Loss (por batch): %.5f\\n\", $avg_loss;\n",
    "\n",
    "\n",
    "\n",
    "    return ($tn, $fp, $fn, $tp);\n",
    "}\n",
    "\n",
    "\n",
    "my ($tn, $fp, $fn, $tp) = final_validation_report($net, $test_loader, $loss_fn, $ctx);\n",
    "\n",
    "print \"\\nMatriz de ConfusiÃ³n:\\n\";\n",
    "print \"               Pred_0   Pred_1\\n\";\n",
    "printf \"Real_0      %6d   %6d\\n\", $tn, $fp;\n",
    "printf \"Real_1      %6d   %6d\\n\", $fn, $tp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPerl->load_plugin('Chart::Plotly');\n",
    "\n",
    "use ConfusionMatrixPlot qw(plot_confusion_matrix);\n",
    "\n",
    "# --- Matriz de ConfusiÃ³n --- [$tn, $fp], [$fn, $tp]\n",
    "my $matrix_ref = [\n",
    "    [$tn, $fp],   # Real_0: Pred_0, Pred_1\n",
    "    [$fn, $tp],   # Real_1: Pred_0, Pred_1\n",
    "];\n",
    "my $x_labels_ref = ['Pred_0', 'Pred_1'];\n",
    "my $y_labels_ref = ['Real_0', 'Real_1'];\n",
    "\n",
    "#my $color_scale = 'Hot';  # Puedes cambiar a 'Cividis', 'Hot', etc.\n",
    "\n",
    "my $plot = plot_confusion_matrix($matrix_ref, $x_labels_ref, $y_labels_ref, 'Matriz de ConfusiÃ³n','Viridis');\n",
    "$plot;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"PrecisiÃ³n en el entrenamiento por Ã©poca:\\n\";\n",
    "for my $i (0..$#acc_train_hist) {\n",
    "    printf(\"Ã‰poca %2d: %.4f\\n\", $i+1, $acc_train_hist[$i]);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ver imÃ¡genes de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preparar referencias:\n",
    "my $error_indices_ref = [];\n",
    "my $predicted_labels_ref = [];\n",
    "\n",
    "# 3. Obtener los errores recorriendo de nuevo:\n",
    "my $index = 0;\n",
    "$test_loader->reset();\n",
    "while (my ($data, $label, $paths) = $test_loader->next) {\n",
    "    if ($data->shape->[1] == $image_size && $data->shape->[3] == 3) {\n",
    "        $data = $data->transpose([0, 3, 1, 2]);\n",
    "    }\n",
    "    $data  = $data->as_in_context($ctx);\n",
    "    $label = $label->as_in_context($ctx);\n",
    "\n",
    "    my $output = $net->($data);\n",
    "    my $preds = $output->argmax(axis => 1);\n",
    "    my @preds_arr  = @{$preds->aspdl->unpdl};\n",
    "    my @labels_arr = @{$label->aspdl->unpdl};\n",
    "\n",
    "    for my $i (0 .. $#labels_arr) {\n",
    "        push @$predicted_labels_ref, [$index, $labels_arr[$i], $preds_arr[$i]];\n",
    "\n",
    "        if ($preds_arr[$i] != $labels_arr[$i]) {\n",
    "            push @$error_indices_ref, $index;\n",
    "        }\n",
    "        $index++;\n",
    "    }\n",
    "}\n",
    "\n",
    "# 4. Verificar que estÃ¡n bien:\n",
    "print \"\\nErrores detectados en Ã­ndices: @$error_indices_ref\\n\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GalerÃ­a de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub generar_galeria_errores {\n",
    "    my ($dataset, $error_indices_ref, $predicted_labels_ref, $nombre_base) = @_;\n",
    "\n",
    "    # Crear un hash para buscar rÃ¡pidamente [real, predicho] por Ã­ndice\n",
    "    my %pred_map = map { $_->[0] => [ $_->[1], $_->[2] ] } @$predicted_labels_ref;\n",
    "\n",
    "    my $html = \"<div style='display: flex; flex-wrap: wrap;'>\\n\";\n",
    "\n",
    "    for my $i (@$error_indices_ref) {\n",
    "        my ($img, $label, $path) = $dataset->at($i);\n",
    "        next unless defined $img;\n",
    "\n",
    "        my ($real, $predicho) = @{ $pred_map{$i} // [undef, undef] };\n",
    "        next unless defined $real and defined $predicho;\n",
    "\n",
    "        # Convertir imagen a PDL\n",
    "        my $pdl_img = $img->aspdl->mv(0, 2);  # CHW â†’ HWC\n",
    "        $pdl_img *= 255 if $pdl_img->max <= 1;\n",
    "        $pdl_img = byte($pdl_img);\n",
    "\n",
    "        my ($basename) = $path =~ m{([^/]+\\.png)$};\n",
    "        my $filename = sprintf(\"${nombre_base}_%02d_real_%d_pred_%d.png\", $i, $real, $predicho);\n",
    "        write_true_png($pdl_img, $filename);\n",
    "\n",
    "        # Mostrar tambiÃ©n el path\n",
    "        $html .= \"<div style='margin: 5px; text-align: center; font-size: 11px; max-width: 80px;'>\n",
    "                    <img src='$filename' width='80' style='border: 1px solid #ccc;'><br>\n",
    "                    <b>Real:</b> $real<br><b>Pred:</b> $predicho<br>\n",
    "                    <!--<small>$basename</small><br>-->\n",
    "                    <small style='word-break: break-all;'>$path</small>\n",
    "                  </div>\\n\";\n",
    "    }\n",
    "\n",
    "    $html .= \"</div>\\n\";\n",
    "    IPerl->html($html);\n",
    "}\n",
    "\n",
    "generar_galeria_errores($test_loader->{dataset}, $error_indices_ref, $predicted_labels_ref, 'error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EvaluaciÃ³n Final (test_loader)\n",
    "Bloque para evaluar el modelo ya entrenado en el conjunto de prueba, calcular la precisiÃ³n (accuracy) y ademÃ¡s cÃ³mo guardar y cargar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my ($correct, $total) = (0, 0);\n",
    "\n",
    "$test_loader->reset;\n",
    "while (my ($data, $labels) = $test_loader->next) {\n",
    "    # Convertir a NCHW si vienen en NHWC\n",
    "    $data = $data->transpose([0, 3, 1, 2]) if $data->shape->[1] == $image_size;\n",
    "\n",
    "    my $output = $net->($data);\n",
    "    my $preds = $output->argmax(axis => 1);\n",
    "\n",
    "    my $matches = $preds->equal($labels)->sum->asscalar;\n",
    "    $correct += $matches;\n",
    "    $total   += $labels->shape->[0];\n",
    "}\n",
    "\n",
    "my $acc = $total > 0 ? $correct / $total : 0;\n",
    "printf(\"PrecisiÃ³n en conjunto de prueba: %.2f%%\\n\", 100 * $acc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar el modelo entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $net->save_parameters('modelo_entrenado_aug_01.params');\n",
    "# print \"Modelo guardado como 'modelo_entrenado_aug_01.params'\\n\";"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPerl 0.012",
   "language": "perl",
   "name": "iperl"
  },
  "language_info": {
   "file_extension": ".pl",
   "mimetype": "text/x-perl",
   "name": "perl",
   "version": "5.34.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
